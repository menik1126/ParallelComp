
CondaError: Run 'conda init' before 'conda activate'

Running evaluation for dataset: lcc
n_windows:[3]
model_name:/mnt/Data/xiongjing/llama2chat
multi_gpus:True
torch.cuda.device_count():5
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 138, in <module>
[rank3]:     run_pcw_experiment(**vars(args))
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 57, in run_pcw_experiment
[rank3]:     pcw_model = load_pcw_wrapper(model, cache_dir, right_indentation, max(n_windows), prompt_method=prompt_method, model_class=model_class, accelerator=accelerator, capacity=capacity)
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/model_loaders.py", line 99, in load_pcw_wrapper
[rank3]:     model = model_obj.from_pretrained(model_name,**model_args).eval()
[rank3]:   File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4130, in from_pretrained
[rank3]:     model = cls(config, *model_args, **model_kwargs)
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 32, in __init__
[rank3]:     self.model = LlamaModelPCW(config)
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in __init__
[rank3]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in <listcomp>
[rank3]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank3]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 115, in __init__
[rank3]:     super().__init__(config)
[rank3]: TypeError: LlamaDecoderLayer.__init__() missing 1 required positional argument: 'layer_idx'
W1222 18:57:10.759036 139635123423040 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411510 closing signal SIGTERM
W1222 18:57:10.759272 139635123423040 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411511 closing signal SIGTERM
W1222 18:57:10.759348 139635123423040 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411512 closing signal SIGTERM
W1222 18:57:10.759441 139635123423040 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411514 closing signal SIGTERM
E1222 18:57:10.886059 139635123423040 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 3 (pid: 2411513) of binary: /home/xiongjing/miniconda3/envs/sjh/bin/python
Traceback (most recent call last):
  File "/home/xiongjing/miniconda3/envs/sjh/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    multi_gpu_launcher(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
run_evaluation_longbench_multi_gpu.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-22_18:57:10
  host      : nwonga100.local
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 2411513)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Running evaluation for dataset: repobench-p
n_windows:[3]
model_name:/mnt/Data/xiongjing/llama2chat
multi_gpus:True
torch.cuda.device_count():5
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 138, in <module>
[rank4]:     run_pcw_experiment(**vars(args))
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 57, in run_pcw_experiment
[rank4]:     pcw_model = load_pcw_wrapper(model, cache_dir, right_indentation, max(n_windows), prompt_method=prompt_method, model_class=model_class, accelerator=accelerator, capacity=capacity)
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/model_loaders.py", line 99, in load_pcw_wrapper
[rank4]:     model = model_obj.from_pretrained(model_name,**model_args).eval()
[rank4]:   File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4130, in from_pretrained
[rank4]:     model = cls(config, *model_args, **model_kwargs)
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 32, in __init__
[rank4]:     self.model = LlamaModelPCW(config)
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in __init__
[rank4]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in <listcomp>
[rank4]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank4]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 115, in __init__
[rank4]:     super().__init__(config)
[rank4]: TypeError: LlamaDecoderLayer.__init__() missing 1 required positional argument: 'layer_idx'
n_windows:[3]
model_name:/mnt/Data/xiongjing/llama2chat
multi_gpus:True
torch.cuda.device_count():5
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 138, in <module>
[rank2]:     run_pcw_experiment(**vars(args))
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/run_evaluation_longbench_multi_gpu.py", line 57, in run_pcw_experiment
[rank2]:     pcw_model = load_pcw_wrapper(model, cache_dir, right_indentation, max(n_windows), prompt_method=prompt_method, model_class=model_class, accelerator=accelerator, capacity=capacity)
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/model_loaders.py", line 99, in load_pcw_wrapper
[rank2]:     model = model_obj.from_pretrained(model_name,**model_args).eval()
[rank2]:   File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4130, in from_pretrained
[rank2]:     model = cls(config, *model_args, **model_kwargs)
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 32, in __init__
[rank2]:     self.model = LlamaModelPCW(config)
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in __init__
[rank2]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 105, in <listcomp>
[rank2]:     self.layers = nn.ModuleList([LlamaDecoderLayerPCW(config) for _ in range(config.num_hidden_layers)])
[rank2]:   File "/home/xiongjing/sjh/parallel_window_size/modeling_llama_with_pcw.py", line 115, in __init__
[rank2]:     super().__init__(config)
[rank2]: TypeError: LlamaDecoderLayer.__init__() missing 1 required positional argument: 'layer_idx'
W1222 18:57:21.151594 139710578239296 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411576 closing signal SIGTERM
W1222 18:57:21.152173 139710578239296 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411577 closing signal SIGTERM
W1222 18:57:21.152648 139710578239296 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411578 closing signal SIGTERM
W1222 18:57:21.152736 139710578239296 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 2411579 closing signal SIGTERM
E1222 18:57:21.430704 139710578239296 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 4 (pid: 2411580) of binary: /home/xiongjing/miniconda3/envs/sjh/bin/python
Traceback (most recent call last):
  File "/home/xiongjing/miniconda3/envs/sjh/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    multi_gpu_launcher(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/xiongjing/miniconda3/envs/sjh/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
run_evaluation_longbench_multi_gpu.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-22_18:57:21
  host      : nwonga100.local
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 2411580)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
