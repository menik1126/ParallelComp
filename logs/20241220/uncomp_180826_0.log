2024-12-20 18:09:25,440 - [Process 0/1] - INFO - loading datasets finished
2024-12-20 18:09:25,440 - [Process 0/1] - INFO - model_max_len: 3950
2024-12-20 18:09:25,440 - [Process 0/1] - INFO - output_max_len: 64
2024-12-20 18:09:25,459 - [Process 0/1] - INFO - Max Length is 10337
2024-12-20 18:09:25,459 - [Process 0/1] - INFO - Finish loading dataset
2024-12-20 18:09:25,459 - [Process 0/1] - INFO - get_predicted begin
2024-12-20 18:09:25,512 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:27,718 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:27,718 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 1888])
2024-12-20 18:09:27,952 - [Process 0/1] - INFO - res.shape is :torch.Size([8])
2024-12-20 18:09:28,094 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:31,714 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:31,714 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3950])
2024-12-20 18:09:31,821 - [Process 0/1] - INFO - res.shape is :torch.Size([4])
2024-12-20 18:09:31,945 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:35,488 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:35,488 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3950])
2024-12-20 18:09:36,512 - [Process 0/1] - INFO - res.shape is :torch.Size([27])
2024-12-20 18:09:36,666 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:40,219 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:40,219 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3953])
2024-12-20 18:09:42,806 - [Process 0/1] - INFO - res.shape is :torch.Size([66])
2024-12-20 18:09:42,937 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:46,412 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:46,412 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3951])
2024-12-20 18:09:46,908 - [Process 0/1] - INFO - res.shape is :torch.Size([14])
2024-12-20 18:09:47,040 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:50,601 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:50,601 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3951])
2024-12-20 18:09:51,255 - [Process 0/1] - INFO - res.shape is :torch.Size([18])
2024-12-20 18:09:51,389 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:09:55,053 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:09:55,053 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3951])
2024-12-20 18:09:57,200 - [Process 0/1] - INFO - res.shape is :torch.Size([55])
2024-12-20 18:09:57,300 - [Process 0/1] - INFO - len(per_windows_prompt):2
2024-12-20 18:10:00,519 - [Process 0/1] - INFO - tokenized_inputs_attention_mask.shape is :torch.Size([1, 2])
2024-12-20 18:10:00,519 - [Process 0/1] - INFO - cache['past_attention_mask'].shape is :torch.Size([1, 3580])
2024-12-20 18:10:01,003 - [Process 0/1] - INFO - res.shape is :torch.Size([14])
2024-12-20 18:10:01,061 - [Process 0/1] - INFO - len(per_windows_prompt):2
